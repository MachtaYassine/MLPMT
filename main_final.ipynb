{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Project template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We outline a structured approach for presenting research findings. The framework is divided into several key segments:\n",
    "\n",
    "1. Introduction\n",
    "1. Dataset overview\n",
    "1. Analytics and learning strategies\n",
    "1. Empirical resuts: baseline and robustness \n",
    "1. Conclusion\n",
    "\n",
    "The opening segment encompasses four essential elements:\n",
    "\n",
    "- Contextual Background: What is the larger setting of the study? What makes this area of inquiry compelling? What are the existing gaps or limitations within the current body of research? What are some unanswered yet noteworthy questions?\n",
    "\n",
    "- Project Contributions: What are the specific advancements made by this study, such as in data acquisition, algorithmic development, parameter adjustments, etc.?\n",
    "\n",
    "- Summary of the main empirical results: What is the main statistical statement? is it significant (e.g. statistically or economically)? \n",
    "\n",
    "- Literature and Resource Citations: What are related academic papers? What are the github repositories, expert blogs, or software packages that used in this project? \n",
    "\n",
    "In the dataset profile, one should consider:\n",
    "\n",
    "- The origin and composition of data utilized in the study. If the dataset is original, then provide the source code to ensure reproducibility.\n",
    "\n",
    "- The chronological accuracy of the data points, verifying that the dates reflect the actual availability of information.\n",
    "\n",
    "- A detailed analysis of descriptive statistics, with an emphasis on discussing the importance of the chosen graphs or metrics.\n",
    "\n",
    "The analytics and machine learning methodologies section accounts for:\n",
    "\n",
    "- A detailed explanation of the foundational algorithm.\n",
    "\n",
    "- A description of the data partitioning strategy for training, validation and test.\n",
    "\n",
    "- An overview of the parameter selection and optimization process.\n",
    "\n",
    "To effectively convey the empirical findings, separate the baseline results from the additional robustness tests. Within the primary empirical outcomes portion, include:\n",
    "\n",
    "- Key statistical evaluations (for instance, if presenting a backtest – provide a pnl graph alongside the Sharpe ratio).\n",
    "\n",
    "- Insights into what primarily influences the results, such as specific characteristics or assets that significantly impact performance.\n",
    "\n",
    "The robustness of empirical tests section should detail:\n",
    "\n",
    "- Evaluation of the stability of the principal finding against variations in hyperparameters or algorithmic modifications.\n",
    "\n",
    "Finally, the conclusive synthesis should recapitulate the primary findings, consider external elements that may influence the results, and hint at potential directions for further investigative work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment and global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instal packages\n",
    "!pip install mistralai transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "from mistralai import Mistral\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#whether to use mistral prompting or load datsets online\n",
    "prompt_mistral = input(\"Do you want to use mistral prompting? (y/n): \") # or set to True\n",
    "if prompt_mistral == 'y':\n",
    "    prompt_mistral = True\n",
    "else:\n",
    "    prompt_mistral = False\n",
    "    \n",
    "if prompt_mistral:\n",
    "    api_key_file = input(\"Enter the path to the API key file: \")\n",
    "    with open(api_key_file, 'r') as file:\n",
    "        api_key = file.read().strip()\n",
    "        \n",
    "else:\n",
    "    api_key = None\n",
    "    print(\"Using datasets on Yassine's webpage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "# load comunications fomc\n",
    "if os.path.exists('./communications.csv'):\n",
    "    commuications = pd.read_csv('./communications.csv')\n",
    "    print('Dataset loaded.')\n",
    "else:\n",
    "    print('Installing dataset...')\n",
    "    !curl -L -o ./fomc-meeting-statements-and-minutes.zip https://www.kaggle.com/api/v1/datasets/download/vladtasca/fomc-meeting-statements-and-minutes\n",
    "    !unzip ./fomc-meeting-statements-and-minutes.zip -d ./fomc-meeting-statements-and-minutes\n",
    "    !mv ./fomc-meeting-statements-and-minutes/communications.csv ./communications.csv\n",
    "    !rm ./fomc-meeting-statements-and-minutes.zip\n",
    "    !rm -r ./fomc-meeting-statements-and-minutes\n",
    "    \n",
    "    commuications = pd.read_csv('./communications.csv')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Georgia Tech's dataset\n",
    "splits = {'train': 'train.csv', 'test': 'test.csv'}\n",
    "df_train = pd.read_csv(\"hf://datasets/gtfintechlab/fomc_communication/\" + splits[\"train\"])\n",
    "df_test = pd.read_csv(\"hf://datasets/gtfintechlab/fomc_communication/\" + splits[\"test\"])\n",
    "\n",
    "georgia_tech_df = pd.concat([df_train, df_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_date</th>\n",
       "      <th>INTDSRUSM193N</th>\n",
       "      <th>evolution</th>\n",
       "      <th>evolution_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>5.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>4.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>5.34</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.908397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2.996255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>2000-05-01</td>\n",
       "      <td>5.71</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    observation_date  INTDSRUSM193N  evolution  evolution_pct\n",
       "600       2000-01-01           5.00        NaN            NaN\n",
       "601       2000-02-01           5.24       0.24       4.800000\n",
       "602       2000-03-01           5.34       0.10       1.908397\n",
       "603       2000-04-01           5.50       0.16       2.996255\n",
       "604       2000-05-01           5.71       0.21       3.818182\n",
       "..               ...            ...        ...            ...\n",
       "855       2021-04-01           0.25       0.00       0.000000\n",
       "856       2021-05-01           0.25       0.00       0.000000\n",
       "857       2021-06-01           0.25       0.00       0.000000\n",
       "858       2021-07-01           0.25       0.00       0.000000\n",
       "859       2021-08-01           0.25       0.00       0.000000\n",
       "\n",
       "[260 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load interest rate Data\n",
    "# Define the URL for the CSV download\n",
    "csv_url = \"https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1320&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=INTDSRUSM193N&scale=left&cosd=1950-01-01&coed=2021-08-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2024-12-18&revision_date=2024-12-18&nd=1950-01-01\"\n",
    "\n",
    "#Interest Rates, Discount Rate for United States\n",
    "\n",
    "# Download the CSV file into a DataFrame\n",
    "Int_R = pd.read_csv(csv_url)\n",
    "#keep observations from 2000 onwards\n",
    "Int_R=Int_R[Int_R['observation_date']>='2000-01-01']\n",
    "Int_R['evolution']=Int_R['INTDSRUSM193N'].diff(1)\n",
    "Int_R['evolution_pct']=Int_R['INTDSRUSM193N'].pct_change(1)*100\n",
    "Int_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_date</th>\n",
       "      <th>CPIAUCSL</th>\n",
       "      <th>evolution</th>\n",
       "      <th>evolution_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>169.300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>170.000</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.413467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>171.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>170.900</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.058480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>2000-05-01</td>\n",
       "      <td>171.200</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.175541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>313.534</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.154928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>314.121</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.187221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>314.686</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.179867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>315.454</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.244053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>316.441</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.312882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    observation_date  CPIAUCSL  evolution  evolution_pct\n",
       "636       2000-01-01   169.300        NaN            NaN\n",
       "637       2000-02-01   170.000      0.700       0.413467\n",
       "638       2000-03-01   171.000      1.000       0.588235\n",
       "639       2000-04-01   170.900     -0.100      -0.058480\n",
       "640       2000-05-01   171.200      0.300       0.175541\n",
       "..               ...       ...        ...            ...\n",
       "930       2024-07-01   313.534      0.485       0.154928\n",
       "931       2024-08-01   314.121      0.587       0.187221\n",
       "932       2024-09-01   314.686      0.565       0.179867\n",
       "933       2024-10-01   315.454      0.768       0.244053\n",
       "934       2024-11-01   316.441      0.987       0.312882\n",
       "\n",
       "[299 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#consumer price index\n",
    "# Define the URL for the CSV download\n",
    "csv_url = \"https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1320&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=CPIAUCSL&scale=left&cosd=1947-01-01&coed=2024-11-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=3&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2024-12-18&revision_date=2024-12-18&nd=1947-01-01\"\n",
    "\n",
    "#Consumer Price Index for All Urban Consumers: All Items in U.S. City Average\n",
    "\n",
    "# Download the CSV file into a DataFrame\n",
    "CPI = pd.read_csv(csv_url)\n",
    "#keep observations from 2000 onwards\n",
    "CPI=CPI[CPI['observation_date']>='2000-01-01']\n",
    "CPI['evolution']=CPI['CPIAUCSL'].diff(1)\n",
    "CPI['evolution_pct']=CPI['CPIAUCSL'].pct_change(1)*100\n",
    "CPI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_date</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>evolution</th>\n",
       "      <th>evolution_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-2.439024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>2000-05-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.263158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    observation_date  UNRATE  evolution  evolution_pct\n",
       "624       2000-01-01     4.0        NaN            NaN\n",
       "625       2000-02-01     4.1        0.1       2.500000\n",
       "626       2000-03-01     4.0       -0.1      -2.439024\n",
       "627       2000-04-01     3.8       -0.2      -5.000000\n",
       "628       2000-05-01     4.0        0.2       5.263158"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unemployment rate\n",
    "# Define the URL for the CSV download\n",
    "csv_url = \"https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1320&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=UNRATE&scale=left&cosd=1948-01-01&coed=2024-11-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=3&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2024-12-18&revision_date=2024-12-18&nd=1948-01-01\"\n",
    "\n",
    "#Unepmloyment Rate\n",
    "\n",
    "# Download the CSV file into a DataFrame\n",
    "UR = pd.read_csv(csv_url)\n",
    "#keep observations from 2000 onwards\n",
    "UR=UR[UR['observation_date']>='2000-01-01']\n",
    "UR['evolution']=UR['UNRATE'].diff(1)\n",
    "UR['evolution_pct']=UR['UNRATE'].pct_change(1)*100\n",
    "UR.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variable_name(var):\n",
    "    return [name for name in globals() if globals()[name] is var][0]\n",
    "\n",
    "\n",
    "def analyze_monetary_policy(df,api_key,prompt_mistral=prompt_mistral,use_checkpoints=True):\n",
    "    df_name = get_variable_name(df)\n",
    "    if not prompt_mistral:\n",
    "        if df_name == 'commuications':\n",
    "            checkpoint = pd.read_csv('https://MachtaYassine.github.io/datasets/communications-mistral-prompted.csv',index_col=0)\n",
    "        elif df_name == 'gerogia_tech_df':\n",
    "            checkpoint = pd.read_csv('https://MachtaYassine.github.io/datasets/georgia-tech-mistral-prompted.csv',index_col=0)\n",
    "        else:\n",
    "            raise ValueError('The dataset is not recognized. Please set prompt_mistral to True.')\n",
    "        return checkpoint\n",
    "    model = \"mistral-large-latest\"\n",
    "    client = Mistral(api_key=api_key)\n",
    "    df_name = get_variable_name(df)\n",
    "    if use_checkpoints and os.path.exists(f'{df_name}_checpoint.csv'):\n",
    "        checkpoint = pd.read_csv(f'{df_name}_checpoint.csv')\n",
    "        print('Checkpoint loaded.')\n",
    "    else:\n",
    "        checkpoint = pd.DataFrame(columns=['text'])\n",
    "\n",
    "\n",
    "    for text in tqdm(df['Text'].values[len(checkpoint):]):\n",
    "        chat_response = client.chat.complete(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Act as a financial analyst. What is the monetary policy hawkishness of this text? \\\n",
    "    Please choose an answer from hawkish, dovish, neutral or unknown and provide a probability and a short explanation. \\\n",
    "        answer in this structure (no other text) : \\n \\\n",
    "        label: hawkish, \\n probability: 90%, \\n explanation: The text contains a lot of positive words and is likely to be hawkish. \\n \\\n",
    "    Text: {text}\",\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        response_message = chat_response.choices[0].message.content\n",
    "        \n",
    "\n",
    "        checkpoint = checkpoint.append({'text':response_message},ignore_index=True)\n",
    "        time.sleep(2)\n",
    "        checkpoint.to_csv(f'{df_name}_checpoint.csv',index=False)\n",
    "    \n",
    "    return checkpoint\n",
    "\n",
    "\n",
    "def extract_label(text):\n",
    "    if text.find(\"hawkish\") != -1:\n",
    "        return \"hawkish\"\n",
    "    elif text.find(\"dovish\") != -1:\n",
    "        return \"dovish\"\n",
    "    elif text.find(\"neutral\") != -1:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "    \n",
    "def process_checkpoint(checkpoint,source_df):\n",
    "    source_df['label'] = checkpoint['text'].apply(extract_label)\n",
    "    source_df['explanation'] = checkpoint['text'].apply(lambda x: x.split('explanation: ')[1].strip() if x.find('explanation') != -1 else x.split('Explanation: ')[1].strip())\n",
    "    return source_df\n",
    "\n",
    "def check_important_shift_dates(df,steps):\n",
    "    cond=(np.abs(df['label2'].diff(1))>0)\n",
    "    for step in range(2,steps+1):\n",
    "        cond=cond & (np.abs(df['label2'].diff(step))>0)\n",
    "    return cond\n",
    "\n",
    "\n",
    "def plot_monetary_policy(df,label):\n",
    "    # Ensure Date2 is datetime and sorted\n",
    "    df['Date2'] = pd.to_datetime(df['Release Date'])\n",
    "    df = df.sort_values(by='Date2', ascending=False)\n",
    "\n",
    "    # Encode labels\n",
    "    df['label2'] = df[label].apply(lambda x: 1 if x == 'hawkish' else 0 if x == 'neutral' else -1)\n",
    "\n",
    "    # Identify important shifts\n",
    "    df['shift_date'] = check_important_shift_dates(df, 5)\n",
    "\n",
    "    # Initialize subplots\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(20, 15), sharex=True)\n",
    "\n",
    "    # Plot each statement type separately\n",
    "    for ax, (statement_type, group_df) in zip(axes[:2], df.groupby('Type')):\n",
    "        ax.plot(group_df['Date2'], group_df['label2'], marker='o', label=statement_type)\n",
    "        ax.set_title(f'{statement_type} Statements')\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('Label')\n",
    "        ax.legend(title=\"Statement Type\")\n",
    "\n",
    "    # Plot both together in the last subplot\n",
    "    for statement_type, group_df in df.groupby('Type'):\n",
    "        axes[2].plot(group_df['Date2'], group_df['label2'], marker='o', label=statement_type)\n",
    "\n",
    "    # Customize final plot\n",
    "    axes[2].set_title('Combined Monetary Policy Hawkishness')\n",
    "    axes[2].set_xlabel('Date')\n",
    "    axes[2].set_ylabel('Label')\n",
    "    axes[2].legend(title=\"Statement Type\")\n",
    "\n",
    "    # Customize x-ticks across all plots\n",
    "    xticks_labels = [df['Date2'].iloc[i] if i == 0 or i == len(df) - 1 or df['shift_date'].iloc[i] else '' \n",
    "                    for i in range(len(df))]\n",
    "    plt.xticks(df['Date2'], labels=xticks_labels, rotation=90)\n",
    "\n",
    "    # Show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_test= commuications.iloc[:10]\n",
    "checkpoint_test=analyze_monetary_policy(com_test,api_key,prompt_mistral=prompt_mistral,use_checkpoints=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gtfintechlab/FOMC-RoBERTa\", do_lower_case=True, do_basic_tokenize=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"gtfintechlab/FOMC-RoBERTa\", num_labels=3)\n",
    "config = AutoConfig.from_pretrained(\"gtfintechlab/FOMC-RoBERTa\")\n",
    "\n",
    "classifier = pipeline('text-classification', model=model, tokenizer=tokenizer, config=config, device=0, framework=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = classifier(communications['Text'].tolist(),\n",
    "                      batch_size=128, truncation=\"only_first\")\n",
    "communications['RoBERTa_label_raw']=pd.DataFrame(results)['label'].map({'LABEL_0':'dovish','LABEL_1':'hawkish','LABEL_2':'Neutral'})\n",
    "communications['RoBERTa_probability_raw']=pd.DataFrame(results)['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_explanation = classifier(communications['Mistral_explanation'].tolist(),\n",
    "                                    batch_size=128, truncation=\"only_first\")\n",
    "communications['RoBERTa_label_explanation']=pd.DataFrame(results_explanation)['label'].map({'LABEL_0':'dovish','LABEL_1':'hawkish','LABEL_2':'Neutral'})\n",
    "communications['RoBERTa_probability_explanation']=pd.DataFrame(results_explanation)['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_llm_roberta_raw=accuracy_score(communications['label'],communications['RoBERTa_label_raw'])\n",
    "acc_llm_roberta_explanation=accuracy_score(communications['label'],communications['RoBERTa_label_explanation'])\n",
    "acc_roberta_raw_roberta_explanation=accuracy_score(communications['RoBERTa_label_raw'],communications['RoBERTa_label_explanation'])\n",
    "print(f'Accuracy of LLM vs RoBERTa raw: {acc_llm_roberta_raw}')\n",
    "print(f'Accuracy of LLM vs RoBERTa explanation: {acc_llm_roberta_explanation}')\n",
    "print(f'Accuracy of RoBERTa raw vs RoBERTa explanation: {acc_roberta_raw_roberta_explanation}')\n",
    "#accuracy by type (Minute/ Statement)\n",
    "print('\\n'+'---'*20+'\\n')\n",
    "for t in ['Minute','Statement']:\n",
    "    acc_llm_roberta_raw=accuracy_score(communications[communications['Type']==t]['label'],communications[communications['Type']==t]['RoBERTa_label_raw'])\n",
    "    acc_llm_roberta_explanation=accuracy_score(communications[communications['Type']==t]['label'],communications[communications['Type']==t]['RoBERTa_label_explanation'])\n",
    "    acc_roberta_raw_roberta_explanation=accuracy_score(communications[communications['Type']==t]['RoBERTa_label_raw'],communications[communications['Type']==t]['RoBERTa_label_explanation'])\n",
    "    print(f'Accuracy of LLM vs RoBERTa raw for {t}: {acc_llm_roberta_raw}') \n",
    "    print(f'Accuracy of LLM vs RoBERTa explanation for {t}: {acc_llm_roberta_explanation}')\n",
    "    print(f'Accuracy of RoBERTa raw vs RoBERTa explanation for {t}: {acc_roberta_raw_roberta_explanation}')\n",
    "    print('\\n'+'---'*20+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Compute overall accuracies\n",
    "acc_llm_roberta_raw = accuracy_score(communications['label'], communications['RoBERTa_label_raw'])\n",
    "acc_llm_roberta_explanation = accuracy_score(communications['label'], communications['RoBERTa_label_explanation'])\n",
    "acc_roberta_raw_roberta_explanation = accuracy_score(communications['RoBERTa_label_raw'], communications['RoBERTa_label_explanation'])\n",
    "\n",
    "# Accuracy by type\n",
    "types = ['Minute', 'Statement']\n",
    "accuracies_by_type = {\n",
    "    'LLM vs RoBERTa Raw': [],\n",
    "    'LLM vs RoBERTa Explanation': [],\n",
    "    'RoBERTa Raw vs Explanation': []\n",
    "}\n",
    "\n",
    "for t in types:\n",
    "    acc_llm_roberta_raw = accuracy_score(\n",
    "        communications[communications['Type'] == t]['label'], \n",
    "        communications[communications['Type'] == t]['RoBERTa_label_raw']\n",
    "    )\n",
    "    acc_llm_roberta_explanation = accuracy_score(\n",
    "        communications[communications['Type'] == t]['label'], \n",
    "        communications[communications['Type'] == t]['RoBERTa_label_explanation']\n",
    "    )\n",
    "    acc_roberta_raw_roberta_explanation = accuracy_score(\n",
    "        communications[communications['Type'] == t]['RoBERTa_label_raw'], \n",
    "        communications[communications['Type'] == t]['RoBERTa_label_explanation']\n",
    "    )\n",
    "\n",
    "    accuracies_by_type['LLM vs RoBERTa Raw'].append(acc_llm_roberta_raw)\n",
    "    accuracies_by_type['LLM vs RoBERTa Explanation'].append(acc_llm_roberta_explanation)\n",
    "    accuracies_by_type['RoBERTa Raw vs Explanation'].append(acc_roberta_raw_roberta_explanation)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Overall accuracies\n",
    "categories = ['LLM vs RoBERTa Raw', 'LLM vs RoBERTa Explanation', 'RoBERTa Raw vs Explanation']\n",
    "overall_accuracies = [acc_llm_roberta_raw, acc_llm_roberta_explanation, acc_roberta_raw_roberta_explanation]\n",
    "\n",
    "ax[0].bar(categories, overall_accuracies, color=['blue', 'green', 'orange'])\n",
    "ax[0].set_title('Overall Accuracy')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_ylim(0, 1)\n",
    "ax[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Accuracy by type\n",
    "width = 0.2\n",
    "x = np.arange(len(types))\n",
    "\n",
    "for i, (key, values) in enumerate(accuracies_by_type.items()):\n",
    "    ax[1].bar(x + i * width, values, width, label=key)\n",
    "\n",
    "ax[1].set_title('Accuracy by Type')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].set_xlabel('Communication Type')\n",
    "ax[1].set_xticks(x + width)\n",
    "ax[1].set_xticklabels(types)\n",
    "ax[1].legend()\n",
    "ax[1].set_ylim(0, 1)\n",
    "ax[1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=copy.deepcopy(communications)\n",
    "# Ensure Date2 is datetime and sorted\n",
    "df['Date2'] = pd.to_datetime(df['Release Date'])\n",
    "df = df.sort_values(by='Date2', ascending=False)\n",
    "\n",
    "\n",
    "# Encode labels\n",
    "df['label2'] = df['RoBERTa_label_explanation'].apply(lambda x: 1 if x == 'hawkish' else 0 if x == 'Neutral' else -1)\n",
    "\n",
    "# Identify important shifts\n",
    "df['shift_date'] = check_important_shift_dates(df, 5)\n",
    "\n",
    "# Initialize subplots\n",
    "fig, axes = plt.subplots(3, 3, figsize=(40, 15), sharex=True)\n",
    "\n",
    "# Plot each statement type separately\n",
    "for i, (statement_type, group_df) in enumerate(df.groupby('Type')):\n",
    "        for j, variable in enumerate([Int_R,UR,CPI]):\n",
    "            axes[i,j].plot(group_df['Date2'], group_df['label2'], marker='o', label=statement_type)\n",
    "            axes[i,j].set_title(f'Type : {statement_type}')\n",
    "            axes[i,j].set_xlabel('Date')\n",
    "            axes[i,j].set_ylabel('Label')\n",
    "            axes[i,j].legend(title=\"Statement Type\")\n",
    "            \n",
    "            ax2 = axes[i,j].twinx()  # This creates a second y-axis sharing the same x-axis\n",
    "            ax2.plot(variable['observation_date'], variable['evolution'], color='tab:red', label='Interest Rate')\n",
    "            ax2.set_ylabel('Interest Rate', color='tab:red')  # Set the y-axis label for the second plot\n",
    "            ax2.set_xticks(jan_first_dates)\n",
    "            ax2.set_xticklabels(jan_first_dates.dt.strftime('%Y'), rotation=45, ha='right')\n",
    "    \n",
    "            # Optional: Set a legend for the second y-axis\n",
    "            ax2.legend(title=\"Interest Rate\", loc='upper right')\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "# Plot both together in the last subplot\n",
    "for statement_type, group_df in df.groupby('Type'):\n",
    "    for j, variable in enumerate([Int_R,UR,CPI]):\n",
    "        axes[2,j].plot(group_df['Date2'], group_df['label2'], marker='o', label=statement_type)\n",
    "        axes[2,j].set_title('Combined Monetary Policy Hawkishness')\n",
    "        axes[2,j].set_xlabel('Date')\n",
    "        axes[2,j].set_ylabel('Label')\n",
    "        axes[2,j].legend(title=\"Statement Type\")\n",
    "\n",
    "        ax2 = axes[2,j].twinx()\n",
    "        ax2.plot(variable['observation_date'], variable['evolution'], color='tab:red', label='Interest Rate')\n",
    "        ax2.set_ylabel('Interest Rate', color='tab:red')\n",
    "        ax2.set_xticks(jan_first_dates)\n",
    "        ax2.set_xticklabels(jan_first_dates.dt.strftime('%Y'), rotation=45, ha='right')\n",
    "        ax2.legend(title=\"Interest Rate\", loc='upper right')\n",
    "        \n",
    "        \n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def check_months_apart(dates, x,months,before):\n",
    "    if len(dates) < months:\n",
    "        return False\n",
    "    # print(dates)\n",
    "    # print(x)\n",
    "    # print(dates.iloc[-1])\n",
    "    # print((x - dates.iloc[-1]))\n",
    "    # print('-------------------')\n",
    "    return (x - dates.iloc[-1]).days >= (months-1)*30 if before else (dates.iloc[-1] - x).days >= (months-1)*30\n",
    "\n",
    "def calculate_evolution(df, date_col, value_col, x,months, before=True):\n",
    "    filtered_df = df[df[date_col] <= x] if before else df[df[date_col] >= x]\n",
    "    sorted_df = filtered_df.sort_values(by=date_col, ascending=not before).head(months)\n",
    "    if check_months_apart(sorted_df[date_col], x,months,before):\n",
    "        # print(f\"Date: {x} - Sum: {round(sorted_df[value_col].sum(), 2)}\")\n",
    "        # print(sorted_df)\n",
    "        return round(sorted_df[value_col].sum(), 2)\n",
    "    return np.nan\n",
    "\n",
    "for months in [3, 6, 12]:\n",
    "    for before in [True, False]:\n",
    "        print(f\"Months: {months} - Before: {before}\")\n",
    "        df[f\"i_r_{months}_{'before' if before else 'after'}\"] = df['Date2'].apply(\n",
    "            lambda x: calculate_evolution(Int_R, 'observation_date', 'evolution', x, months, before)\n",
    "        )\n",
    "        df[f\"cpi_{months}_{'before' if before else 'after'}\"] = df['Date2'].apply(\n",
    "            lambda x: calculate_evolution(CPI, 'observation_date', 'evolution', x, months, before)\n",
    "        )\n",
    "        df[f\"u_r_{months}_{'before' if before else 'after'}\"] = df['Date2'].apply(\n",
    "            lambda x: calculate_evolution(UR, 'observation_date', 'evolution', x, months, before)\n",
    "        )\n",
    "#number of nan rows in the columns that contains Nans\n",
    "df.isnull().sum()[df.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import accuracy_score\n",
    "df_dropped_na=df.dropna()\n",
    "def evaluate_kmeans(df,clustering_algorithms):\n",
    "    # Drop missing values\n",
    "    df_dropped_na = df.dropna()\n",
    "\n",
    "    # Define feature combinations\n",
    "    feature_sets = {\n",
    "        'features_3_before': ['i_r_3_before', 'cpi_3_before', 'u_r_3_before'],\n",
    "        'features_3_after': ['i_r_3_after', 'cpi_3_after', 'u_r_3_after'],\n",
    "        'features_3_all': ['i_r_3_before', 'cpi_3_before', 'u_r_3_before', 'i_r_3_after', 'cpi_3_after', 'u_r_3_after'],\n",
    "        'features_6_before': ['i_r_6_before', 'cpi_6_before', 'u_r_6_before'],\n",
    "        'features_6_after': ['i_r_6_after', 'cpi_6_after', 'u_r_6_after'],\n",
    "        'features_6_all': ['i_r_6_before', 'cpi_6_before', 'u_r_6_before', 'i_r_6_after', 'cpi_6_after', 'u_r_6_after'],\n",
    "        'features_12_before': ['i_r_12_before', 'cpi_12_before', 'u_r_12_before'],\n",
    "        'features_12_after': ['i_r_12_after', 'cpi_12_after', 'u_r_12_after'],\n",
    "        'features_12_all': ['i_r_12_before', 'cpi_12_before', 'u_r_12_before', 'i_r_12_after', 'cpi_12_after', 'u_r_12_after'],\n",
    "        'features_after': ['i_r_3_after', 'cpi_3_after', 'u_r_3_after','i_r_6_after', 'cpi_6_after', 'u_r_6_after','i_r_12_after', 'cpi_12_after', 'u_r_12_after'],\n",
    "        'features_before': ['i_r_3_before', 'cpi_3_before', 'u_r_3_before','i_r_6_before', 'cpi_6_before', 'u_r_6_before','i_r_12_before', 'cpi_12_before', 'u_r_12_before'],\n",
    "        'features_all':['i_r_3_before', 'cpi_3_before', 'u_r_3_before','i_r_6_before', 'cpi_6_before', 'u_r_6_before','i_r_12_before', 'cpi_12_before', 'u_r_12_before','i_r_3_after', 'cpi_3_after', 'u_r_3_after','i_r_6_after', 'cpi_6_after', 'u_r_6_after','i_r_12_after', 'cpi_12_after', 'u_r_12_after']\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, features in feature_sets.items():\n",
    "        # Extract features\n",
    "        X = df_dropped_na[features]\n",
    "        # Compute accuracies with label switching\n",
    "        true_labels = df_dropped_na['label2'].values\n",
    "        \n",
    "\n",
    "        for algo_name, algorithm in clustering_algorithms.items():\n",
    "            # Fit clustering algorithm\n",
    "            model = algorithm.fit(X)\n",
    "            labels = model.labels_ if hasattr(model, 'labels_') else model.predict(X)\n",
    "\n",
    "            # Compute accuracies with label switching\n",
    "            acc1 = accuracy_score(true_labels, [-1 if x == 0 else 0 if x == 1 else 1 for x in labels])\n",
    "            acc2 = accuracy_score(true_labels, labels)\n",
    "            acc3 = accuracy_score(true_labels, [1 if x == 0 else 0 if x == 1 else -1 for x in labels])\n",
    "\n",
    "            best_accuracy = max(acc1, acc2, acc3)\n",
    "            results[f'{name}_{algo_name}'] = {\n",
    "                'acc_original': acc2,\n",
    "                'acc_switch_1': acc1,\n",
    "                'acc_switch_2': acc3,\n",
    "                'best_accuracy': best_accuracy\n",
    "            }\n",
    "\n",
    "    # Sort results by best accuracy\n",
    "    sorted_results = dict(sorted(results.items(), key=lambda x: x[1]['best_accuracy'], reverse=True))\n",
    "    \n",
    "    best_accuracy,best_features=sorted_results[list(sorted_results.keys())[0]]['best_accuracy'],list(sorted_results.keys())[0]\n",
    "    return sorted_results,best_accuracy,best_features\n",
    "\n",
    "# Example usage\n",
    "best_results,best_accuracy,best_features = evaluate_kmeans(df, {\n",
    "    'kmeans': KMeans(n_clusters=3, random_state=0),\n",
    "    'agg': AgglomerativeClustering(n_clusters=3),\n",
    "    'dbscan': DBSCAN(eps=0.5, min_samples=5)\n",
    "})\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n",
    "print(f\"Best features: {best_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"best\" predictions are those with 3 months before and after drop 6 and 12 months\n",
    "df.drop(['i_r_6_before', 'cpi_6_before', 'u_r_6_before','i_r_6_after', 'cpi_6_after', 'u_r_6_after','i_r_12_before', 'cpi_12_before', 'u_r_12_before','i_r_12_after', 'cpi_12_after', 'u_r_12_after'], axis=1, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import accuracy_score\n",
    "df_dropped_na=df.dropna()\n",
    "def evaluate_kmeans(df,clustering_algorithms):\n",
    "    # Drop missing values\n",
    "    df_dropped_na = df.dropna()\n",
    "\n",
    "    # Define feature combinations\n",
    "    feature_sets = {\n",
    "        'features_3_before': ['i_r_3_before', 'cpi_3_before', 'u_r_3_before'],\n",
    "        'features_3_after': ['i_r_3_after', 'cpi_3_after', 'u_r_3_after'],\n",
    "        'features_3_all': ['i_r_3_before', 'cpi_3_before', 'u_r_3_before', 'i_r_3_after', 'cpi_3_after', 'u_r_3_after'],\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, features in feature_sets.items():\n",
    "        # Extract features\n",
    "        X = df_dropped_na[features]\n",
    "        # Compute accuracies with label switching\n",
    "        true_labels = df_dropped_na['label2'].values\n",
    "        \n",
    "\n",
    "        for algo_name, algorithm in clustering_algorithms.items():\n",
    "            # Fit clustering algorithm\n",
    "            model = algorithm.fit(X)\n",
    "            labels = model.labels_ if hasattr(model, 'labels_') else model.predict(X)\n",
    "\n",
    "            # Compute accuracies with label switching\n",
    "            acc1 = accuracy_score(true_labels, [-1 if x == 0 else 0 if x == 1 else 1 for x in labels])\n",
    "            acc2 = accuracy_score(true_labels, labels)\n",
    "            acc3 = accuracy_score(true_labels, [1 if x == 0 else 0 if x == 1 else -1 for x in labels])\n",
    "\n",
    "            best_accuracy = max(acc1, acc2, acc3)\n",
    "            results[f'{name}_{algo_name}'] = {\n",
    "                'acc_original': acc2,\n",
    "                'acc_switch_1': acc1,\n",
    "                'acc_switch_2': acc3,\n",
    "                'best_accuracy': best_accuracy\n",
    "            }\n",
    "\n",
    "    # Sort results by best accuracy\n",
    "    sorted_results = dict(sorted(results.items(), key=lambda x: x[1]['best_accuracy'], reverse=True))\n",
    "    \n",
    "    best_accuracy,best_features=sorted_results[list(sorted_results.keys())[0]]['best_accuracy'],list(sorted_results.keys())[0]\n",
    "    return sorted_results,best_accuracy,best_features\n",
    "\n",
    "# Example usage\n",
    "best_results,best_accuracy,best_features = evaluate_kmeans(df, {\n",
    "    'kmeans': KMeans(n_clusters=3, random_state=0),\n",
    "    'agg': AgglomerativeClustering(n_clusters=3),\n",
    "    'dbscan': DBSCAN(eps=0.5, min_samples=5)\n",
    "})\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n",
    "print(f\"Best features: {best_features}\")\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "skfin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
